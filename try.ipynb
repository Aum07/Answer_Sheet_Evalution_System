{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ed5d9b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 TESTING MODEL WITH CORRECT FEATURE ORDER\n",
      "=============================================\n",
      "✅ Test data created with correct feature order\n",
      "Shape: (1, 10)\n",
      "✅ Model and scaler loaded successfully\n",
      "✅ Data scaled successfully\n",
      "\n",
      "🎯 PREDICTION RESULT:\n",
      "Predicted Score: 2\n",
      "\n",
      "✅ SUCCESS! Model working correctly!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aumbh\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:347: InconsistentVersionWarning: Trying to unpickle estimator StandardScaler from version 1.6.1 when using version 1.3.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "print(\"🔍 TESTING MODEL WITH CORRECT FEATURE ORDER\")\n",
    "print(\"=\" * 45)\n",
    "\n",
    "# Your data with CORRECT feature order (matching training)\n",
    "data = {\n",
    "    'Semantic Similarity': [0.775255],\n",
    "    'Length Ratio': [0.147485],\n",
    "    'question_student_similarity': [0.761586],\n",
    "    'POS_noun_ratio_diff': [-0.057548],\n",
    "    'POS_similarity': [0.893383],  # This was 5th in training\n",
    "    'flesch_kincaid_ratio': [0.605556],  # This was 6th in training\n",
    "    'POS_pos_diversity_diff': [0.267306],  # This was 7th in training\n",
    "    'POS_verb_ratio_diff': [-0.004448],  # This was 8th in training\n",
    "    'POS_adv_ratio_diff': [0.107451],  # This was 9th in training\n",
    "    'POS_adj_ratio_diff': [-0.09633]  # This was 10th in training\n",
    "}\n",
    "\n",
    "# Create DataFrame with correct order\n",
    "test_df = pd.DataFrame(data)\n",
    "print(\"✅ Test data created with correct feature order\")\n",
    "print(f\"Shape: {test_df.shape}\")\n",
    "\n",
    "try:\n",
    "    # Load model and scaler\n",
    "    scaler = joblib.load('scaler.pkl')\n",
    "    model = joblib.load('optimized_logistic_at_model.pkl')\n",
    "    print(\"✅ Model and scaler loaded successfully\")\n",
    "    \n",
    "    # Scale the data\n",
    "    scaled_data = scaler.transform(test_df)\n",
    "    print(\"✅ Data scaled successfully\")\n",
    "    \n",
    "    # Make prediction\n",
    "    prediction = model.predict(scaled_data)\n",
    "    print(f\"\\n🎯 PREDICTION RESULT:\")\n",
    "    print(f\"Predicted Score: {prediction[0]}\")\n",
    "    \n",
    "    print(\"\\n✅ SUCCESS! Model working correctly!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61aa0015",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 PDF files to process...\n",
      "Processing 1/2: Aarya_AI.pdf\n",
      "Processing 2/2: Aditya_AI.pdf\n",
      "\n",
      "Processing complete! Check formatted_outputs for results.\n",
      "Created 2 PDF templates, 2 text templates, and 1 Excel summary.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "from pathlib import Path\n",
    "import PyPDF2\n",
    "import pandas as pd\n",
    "from typing import List, Dict, Any\n",
    "import re\n",
    "from datetime import datetime\n",
    "from reportlab.lib.pagesizes import letter, A4\n",
    "from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Table, TableStyle\n",
    "from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle\n",
    "from reportlab.lib.units import inch\n",
    "from reportlab.lib import colors\n",
    "\n",
    "class PDFTemplateProcessor:\n",
    "    def __init__(self, input_directory: str, output_directory: str = \"formatted_outputs\"):\n",
    "        self.input_directory = Path(input_directory)\n",
    "        self.output_directory = Path(output_directory)\n",
    "        self.output_directory.mkdir(exist_ok=True)\n",
    "        \n",
    "    def extract_text_from_pdf(self, pdf_path: Path) -> str:\n",
    "        \"\"\"Extract all text from a PDF file\"\"\"\n",
    "        try:\n",
    "            with open(pdf_path, 'rb') as file:\n",
    "                pdf_reader = PyPDF2.PdfReader(file)\n",
    "                full_text = \"\"\n",
    "                \n",
    "                for page_num, page in enumerate(pdf_reader.pages):\n",
    "                    page_text = page.extract_text()\n",
    "                    full_text += f\"\\n--- PAGE {page_num + 1} ---\\n\"\n",
    "                    full_text += page_text + \"\\n\"\n",
    "                \n",
    "                return full_text\n",
    "        except Exception as e:\n",
    "            return f\"Error extracting text: {str(e)}\"\n",
    "    \n",
    "    def parse_extracted_text(self, text: str, filename: str) -> Dict[str, Any]:\n",
    "        \"\"\"Parse extracted text into structured format\"\"\"\n",
    "        lines = text.split('\\n')\n",
    "        \n",
    "        # Initialize structured data\n",
    "        parsed_data = {\n",
    "            'document_name': filename,\n",
    "            'extraction_date': datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "            'total_lines': len([line for line in lines if line.strip()]),\n",
    "            'sections': [],\n",
    "            'full_text': text\n",
    "        }\n",
    "        \n",
    "        # Group text into sections\n",
    "        current_section = {'title': 'Main Content', 'content': []}\n",
    "        \n",
    "        for line in lines:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "                \n",
    "            # Check if line looks like a header/title\n",
    "            if (line.isupper() and len(line) < 100) or \\\n",
    "               (line.startswith('---') and line.endswith('---')) or \\\n",
    "               any(keyword in line.lower() for keyword in ['chapter', 'section', 'part', 'question']):\n",
    "                \n",
    "                # Save previous section if it has content\n",
    "                if current_section['content']:\n",
    "                    parsed_data['sections'].append(current_section)\n",
    "                \n",
    "                # Start new section\n",
    "                current_section = {'title': line, 'content': []}\n",
    "            else:\n",
    "                current_section['content'].append(line)\n",
    "        \n",
    "        # Add the last section\n",
    "        if current_section['content']:\n",
    "            parsed_data['sections'].append(current_section)\n",
    "        \n",
    "        return parsed_data\n",
    "    \n",
    "    def create_formatted_template(self, parsed_data: Dict[str, Any], output_path: Path):\n",
    "        \"\"\"Create a formatted PDF template from parsed data\"\"\"\n",
    "        doc = SimpleDocTemplate(str(output_path), pagesize=A4)\n",
    "        styles = getSampleStyleSheet()\n",
    "        story = []\n",
    "        \n",
    "        # Custom styles\n",
    "        title_style = ParagraphStyle(\n",
    "            'CustomTitle',\n",
    "            parent=styles['Heading1'],\n",
    "            fontSize=16,\n",
    "            spaceAfter=30,\n",
    "            alignment=1,  # Center alignment\n",
    "            textColor=colors.darkblue\n",
    "        )\n",
    "        \n",
    "        header_style = ParagraphStyle(\n",
    "            'CustomHeader',\n",
    "            parent=styles['Heading2'],\n",
    "            fontSize=14,\n",
    "            spaceAfter=12,\n",
    "            textColor=colors.darkgreen\n",
    "        )\n",
    "        \n",
    "        content_style = ParagraphStyle(\n",
    "            'CustomContent',\n",
    "            parent=styles['Normal'],\n",
    "            fontSize=10,\n",
    "            spaceAfter=6,\n",
    "            leftIndent=20\n",
    "        )\n",
    "        \n",
    "        # Document header\n",
    "        story.append(Paragraph(\"EXTRACTED PDF CONTENT\", title_style))\n",
    "        story.append(Spacer(1, 20))\n",
    "        \n",
    "        # Document information table\n",
    "        doc_info = [\n",
    "            ['Document Name:', parsed_data['document_name']],\n",
    "            ['Extraction Date:', parsed_data['extraction_date']],\n",
    "            ['Total Lines:', str(parsed_data['total_lines'])],\n",
    "            ['Total Sections:', str(len(parsed_data['sections']))]\n",
    "        ]\n",
    "        \n",
    "        info_table = Table(doc_info, colWidths=[2*inch, 4*inch])\n",
    "        info_table.setStyle(TableStyle([\n",
    "            ('BACKGROUND', (0, 0), (0, -1), colors.lightgrey),\n",
    "            ('TEXTCOLOR', (0, 0), (-1, -1), colors.black),\n",
    "            ('ALIGN', (0, 0), (-1, -1), 'LEFT'),\n",
    "            ('FONTNAME', (0, 0), (-1, -1), 'Helvetica'),\n",
    "            ('FONTSIZE', (0, 0), (-1, -1), 10),\n",
    "            ('BOTTOMPADDING', (0, 0), (-1, -1), 12),\n",
    "            ('GRID', (0, 0), (-1, -1), 1, colors.black)\n",
    "        ]))\n",
    "        \n",
    "        story.append(info_table)\n",
    "        story.append(Spacer(1, 30))\n",
    "        \n",
    "        # Content sections\n",
    "        for i, section in enumerate(parsed_data['sections']):\n",
    "            # Section header\n",
    "            story.append(Paragraph(f\"Section {i+1}: {section['title']}\", header_style))\n",
    "            story.append(Spacer(1, 10))\n",
    "            \n",
    "            # Section content\n",
    "            for line in section['content'][:20]:  # Limit lines per section\n",
    "                if line.strip():\n",
    "                    story.append(Paragraph(line, content_style))\n",
    "            \n",
    "            if len(section['content']) > 20:\n",
    "                story.append(Paragraph(f\"... ({len(section['content']) - 20} more lines)\", content_style))\n",
    "            \n",
    "            story.append(Spacer(1, 20))\n",
    "        \n",
    "        # Build PDF\n",
    "        doc.build(story)\n",
    "    \n",
    "    def create_text_template(self, parsed_data: Dict[str, Any], output_path: Path):\n",
    "        \"\"\"Create a formatted text template from parsed data\"\"\"\n",
    "        with open(output_path, 'w', encoding='utf-8') as f:\n",
    "            f.write(\"=\" * 80 + \"\\n\")\n",
    "            f.write(\"EXTRACTED PDF CONTENT TEMPLATE\\n\")\n",
    "            f.write(\"=\" * 80 + \"\\n\\n\")\n",
    "            \n",
    "            f.write(f\"Document Name: {parsed_data['document_name']}\\n\")\n",
    "            f.write(f\"Extraction Date: {parsed_data['extraction_date']}\\n\")\n",
    "            f.write(f\"Total Lines: {parsed_data['total_lines']}\\n\")\n",
    "            f.write(f\"Total Sections: {len(parsed_data['sections'])}\\n\")\n",
    "            f.write(\"\\n\" + \"-\" * 80 + \"\\n\\n\")\n",
    "            \n",
    "            for i, section in enumerate(parsed_data['sections']):\n",
    "                f.write(f\"SECTION {i+1}: {section['title']}\\n\")\n",
    "                f.write(\"-\" * 50 + \"\\n\")\n",
    "                \n",
    "                for line in section['content']:\n",
    "                    if line.strip():\n",
    "                        f.write(f\"  {line}\\n\")\n",
    "                \n",
    "                f.write(\"\\n\" + \"=\" * 30 + \"\\n\\n\")\n",
    "    \n",
    "    def create_excel_template(self, all_parsed_data: List[Dict[str, Any]], output_path: Path):\n",
    "        \"\"\"Create an Excel template with all extracted data\"\"\"\n",
    "        # Prepare data for Excel\n",
    "        excel_data = []\n",
    "        \n",
    "        for parsed_data in all_parsed_data:\n",
    "            base_row = {\n",
    "                'Document_Name': parsed_data['document_name'],\n",
    "                'Extraction_Date': parsed_data['extraction_date'],\n",
    "                'Total_Lines': parsed_data['total_lines'],\n",
    "                'Total_Sections': len(parsed_data['sections'])\n",
    "            }\n",
    "            \n",
    "            # Add sections as separate columns\n",
    "            for i, section in enumerate(parsed_data['sections'][:10]):  # Limit to 10 sections\n",
    "                base_row[f'Section_{i+1}_Title'] = section['title']\n",
    "                base_row[f'Section_{i+1}_Content'] = '\\n'.join(section['content'][:5])  # First 5 lines\n",
    "            \n",
    "            excel_data.append(base_row)\n",
    "        \n",
    "        # Create DataFrame and save\n",
    "        df = pd.DataFrame(excel_data)\n",
    "        df.to_excel(output_path, index=False)\n",
    "    \n",
    "    def process_all_pdfs(self):\n",
    "        \"\"\"Process all PDFs in the directory and create templates\"\"\"\n",
    "        pdf_files = list(self.input_directory.glob(\"*.pdf\"))\n",
    "        \n",
    "        if not pdf_files:\n",
    "            print(f\"No PDF files found in {self.input_directory}\")\n",
    "            return\n",
    "        \n",
    "        print(f\"Found {len(pdf_files)} PDF files to process...\")\n",
    "        \n",
    "        all_parsed_data = []\n",
    "        \n",
    "        for i, pdf_file in enumerate(pdf_files, 1):\n",
    "            print(f\"Processing {i}/{len(pdf_files)}: {pdf_file.name}\")\n",
    "            \n",
    "            # Extract text\n",
    "            extracted_text = self.extract_text_from_pdf(pdf_file)\n",
    "            \n",
    "            # Parse text\n",
    "            parsed_data = self.parse_extracted_text(extracted_text, pdf_file.name)\n",
    "            all_parsed_data.append(parsed_data)\n",
    "            \n",
    "            # Create individual templates\n",
    "            base_name = pdf_file.stem\n",
    "            \n",
    "            # PDF template\n",
    "            pdf_output = self.output_directory / f\"{base_name}_formatted.pdf\"\n",
    "            self.create_formatted_template(parsed_data, pdf_output)\n",
    "            \n",
    "            # Text template\n",
    "            txt_output = self.output_directory / f\"{base_name}_template.txt\"\n",
    "            self.create_text_template(parsed_data, txt_output)\n",
    "        \n",
    "        # Create combined Excel template\n",
    "        excel_output = self.output_directory / \"all_pdfs_combined_template.xlsx\"\n",
    "        self.create_excel_template(all_parsed_data, excel_output)\n",
    "        \n",
    "        print(f\"\\nProcessing complete! Check {self.output_directory} for results.\")\n",
    "        print(f\"Created {len(pdf_files)} PDF templates, {len(pdf_files)} text templates, and 1 Excel summary.\")\n",
    "\n",
    "# Usage example\n",
    "def main():\n",
    "    # Set your input directory path here\n",
    "    input_dir = r\"E:\\ai_powered_answer_sheet_evalution_system\\backend\\samples\\AI\\New folder\"  # Change this to your PDF directory\n",
    "    \n",
    "    # Initialize processor\n",
    "    processor = PDFTemplateProcessor(input_dir)\n",
    "    \n",
    "    # Process all PDFs\n",
    "    processor.process_all_pdfs()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b965bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eval_sys",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
